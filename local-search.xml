<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>在师大校外访问 532movie (一)</title>
    <link href="/2020/08/532moive1/"/>
    <url>/2020/08/532moive1/</url>
    
    <content type="html"><![CDATA[<p>主要思想是在校内找台机器挂代理, 然后连上这个代理.</p><h1 id="准备工具"><a href="#准备工具" class="headerlink" title="准备工具"></a>准备工具</h1><ul><li>Pulse Secure, 安装及配置参考学校给的<a href="https://vpn.bnu.edu.cn/" target="_blank" rel="noopener">教程</a></li><li>VMware Horizon Client, <a href="https://my.vmware.com/en/web/vmware/downloads/info/slug/desktop_end_user_computing/vmware_horizon_clients/2006" target="_blank" rel="noopener">下载地址</a>, <a href="http://cen.bnu.edu.cn/commit/xsxt/tongzhi/tzdetail.asp?id=423" target="_blank" rel="noopener">马秀麟老师的说明</a></li><li>CCProxy, 免费版就行, 先不用安装, <a href="http://www.ccproxy.com/" target="_blank" rel="noopener">官网</a></li><li>Proxifier, 注册码自行 Google, 百度, <a href="https://www.proxifier.com/" target="_blank" rel="noopener">官网</a></li></ul><h1 id="搭建代理"><a href="#搭建代理" class="headerlink" title="搭建代理"></a>搭建代理</h1><ol><li>用 Pulse Secure 连上师大的 VPN.</li><li>打开 VMware Horizon Client, 第一次操作的时候先添加服务器, 服务器地址为 <code>172.22.92.13</code>. 点 “连接” 后会出现凭据不安全的警告, 直接点 “继续”.<br><img src="/img/532movie/VMwareHorizonClient1.png" srcset="/img/loading.gif" title="添加服务器" alt="添加服务器"></li><li>用户名和密码都是学号, 高年级的同学如果登不上可以试试低年级的号, 如果都不行说明这段时间用不了教学云桌面, 暂时放弃, 过段时间再说.<br><img src="/img/532movie/VMwareHorizonClient2.png" srcset="/img/loading.gif" title="登录" alt="登录"></li><li>随便选一个进去.<br><img src="/img/532movie/VMwareHorizonClient3.png" srcset="/img/loading.gif" title="教学云桌面" alt="教学云桌面"></li><li>进去可能是全屏, 鼠标触下屏幕上边点下 “向下还原” 按钮.<br><img src="/img/532movie/VMwareHorizonClient4.png" srcset="/img/loading.gif" title="向下还原" alt="向下还原"></li><li>选项 -&gt; 共享文件夹, 添加 CCProxy 安装程序所在的文件夹.<br><img src="/img/532movie/VMwareHorizonClient5.png" srcset="/img/loading.gif" title="共享文件夹" alt="共享文件夹"><br>现在在教学云桌面里面应该能找到你共享的文件夹.<br><img src="/img/532movie/VMwareHorizonClient6.png" srcset="/img/loading.gif" title="共享文件夹" alt="共享文件夹"></li><li>在教学云桌面以管理员身份运行 CCProxy 安装程序, 无脑点击 “下一步”. 安装完成后会自动运行, 点击设置, 它会显示教学云桌面的 ip 地址 (图中所示为 <code>172.24.2.50</code>), 记下它.<br><img src="/img/532movie/VMwareHorizonClient7.png" srcset="/img/loading.gif" title="CCProxy" alt="CCProxy"><br>代理服务器已经搭建好了, 现在可以回到自己的机器上连接代理. <strong>要最小化 VMware Horizon Client 而不是关掉它!</strong></li></ol><h1 id="连接代理服务器"><a href="#连接代理服务器" class="headerlink" title="连接代理服务器"></a>连接代理服务器</h1><ol><li>打开 Proxifier, 菜单栏 Profile -&gt; Proxy Servers.<br><img src="/img/532movie/Proxifier1.png" srcset="/img/loading.gif" title="Proxifier" alt="Proxifier"><br>点 “Add…”, Address 为刚刚记下的 ip 地址 (图中所示为 <code>172.24.2.50</code>), 端口为 <code>808</code>, Protocol 选 HTTPS.<br><img src="/img/532movie/Proxifier2.png" srcset="/img/loading.gif" title="Proxifier" alt="Proxifier"></li><li>菜单栏 Profile -&gt; Proxification Rules, 点 “Add…”, 配置如图所示.<br><img src="/img/532movie/Proxifier3.png" srcset="/img/loading.gif" title="Proxifier" alt="Proxifier"><br>点完 “OK” 后应该可以愉快地访问 <a href="http://532movie.bnu.edu.cn/" target="_blank" rel="noopener">532movie</a> 了.</li></ol><h1 id="注"><a href="#注" class="headerlink" title="注"></a>注</h1><ol><li>在使用一段时间后有可能出现教学云桌面自动掉线的情况, 我猜是因为长时间不操作就自动断开, 这时重新操作一遍即可.</li><li>教学云桌面原本是给同学们联系相应软件的操作, 刷大学计算机的题目, 所以在考试周的时候不要用教学云桌面, 教学云桌面有名额限制, 给真正需要的同学留点空间.</li><li>还有其它方法以后再说.</li></ol>]]></content>
    
    
    <categories>
      
      <category>Beijing Normal University</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Beijing Normal University</tag>
      
      <tag>532movie</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>一维最优化问题</title>
    <link href="/2020/03/OptimizationTheory2/"/>
    <url>/2020/03/OptimizationTheory2/</url>
    
    <content type="html"><![CDATA[<p>本文基本上是老师的讲义, 少部分为自己理解或修改.</p><p>首先回忆最优化问题的形式.</p>\begin{equation*}\min_{x \in \R^n} f(x),\quad \st x \in X.\end{equation*}<p>考虑最简单的情况: $n = 1$, 此时考虑的函数为 $f : \R \to \R$, $X$ 可以是 $(-\infty, a]$, $[a, b]$, $[b, +\infty)$, 也可以是这些区间的并集. 为方便起见, 先考虑无约束的一维最优化问题:<br>\begin{equation}\label{equ:notResOneOpt}<br>\min_{x \in \R} f(x).<br>\end{equation}</p><ul><li>它是高维优化问题的基础.</li><li>一般只考虑非线性的 $f$, 线性的情况是平凡的.</li><li>假设 $f \in C^1$, 若 $x^* \in \R$ 是问题 \eqref{equ:notResOneOpt} 的解, 则有 $f’(x^*) = 0$, 于是我们获得了一个必要条件<br>\begin{equation}\label{equ:fpxEqu0}<br>f’(x) = 0.<br>\end{equation}</li></ul><h1 id="Newton-法"><a href="#Newton-法" class="headerlink" title="Newton 法"></a>Newton 法</h1><p><strong>例</strong> $x^2 = 2$, 希望求出正根. 观察函数图像可知正根大于 $1$ 小于 $2$. 我们取初始的 $x = 1$.</p><ol><li><p>$x = 1 + \ep$, $0 &lt; \ep &lt; 1$, 有 $(1 + \ep)^2 = 2$, 展开得 $1 + 2\ep + \ep^2 = 2$ 忽略二次项, 解得 $\ep \approx \dfrac{1}{2}$, 得到 $x \approx 1.5$.</p></li><li><p>$x = 1.5 + \ep$, $0 &lt; \ep &lt; 1$, 有 $(1.5 + \ep)^2 = 2$, 展开得 $2.25 + 3\ep + \ep^2 = 2$ 忽略二次项, 解得 $\ep \approx -\dfrac{1}{12}$, 得到 $x \approx 1.416$.</p></li><li><p>$x = 1.5 - \dfrac{1}{12} + \ep$, $\cdots$</p></li></ol><h2 id="Newton-法的思想"><a href="#Newton-法的思想" class="headerlink" title="Newton 法的思想"></a>Newton 法的思想</h2><p>先猜测一个初值, 然后 $x \approx x_k + \ep$, 前面做的实际上是进行了一个二阶的 Taylor 展开</p>\begin{equation*}P(x_k + \ep) = 0 \Rightarrow P(x_k) + \ep P'(x_k) + O(\ep^2).\end{equation*}<p>由于 $\ep$ 是无穷小量, 可以把 $O(\ep^2)$ 近似为 $0$, 得到一个线性方程, 求解得到</p>\begin{equation*}\ep\approx\dfrac{P(x_k)}{P'(x_k)},\end{equation*}<p>于是得到迭代公式</p>\begin{equation*}x_{k + 1} = x_k - \dfrac{P(x_k)}{P'(x_k)}.\end{equation*}<p>有了 Newton 法的思想后, 可以直接应用到 \eqref{equ:fpxEqu0}, 只需要把 $P(x)$ 替换成 $f’(x)$.</p><h2 id="算法-可靠性及有效性"><a href="#算法-可靠性及有效性" class="headerlink" title="算法, 可靠性及有效性"></a>算法, 可靠性及有效性</h2><p><strong>算法 2.1 (一维问题 Newton 法)</strong></p><p>Step 1. 给定 $\ep &gt; 0$ 作为精度要求 (终止条件). 取 $k = 0$ 及 $x_0$.</p><p>Step 2. 计算 $f’(x_k)$ 及 $f^{\prime\prime}(x_k)$.</p><p>Step 3. $x_{k + 1} = x_k - \dfrac{f’(x_k)}{f^{\prime\prime}(x_k)}$.</p><p>Step 4. 若 $\lrv{f’(x_{k + 1})} &lt; \ep$ 则停止, 输出 $x^* = x_{k + 1}$.</p><p>否则, 取 $x_k = x_{k + 1}$, $k = k + 1$, 进入 Step 2.</p><p>需要对这个算法给出相应的数学分析.</p><ul><li><p>可靠性: 是否 $x_k \to x^*$, $k \to \infty$?</p></li><li><p>有效性: $\lrv{x_k - x^*}$ 收敛到 $0$ 的速度 (作为 $k$ 的函数)?</p></li></ul><p><strong>定理 2.1</strong> 设 $f \in C^2$, $f’(x^*) = 0$, $f^{\prime\prime}(x^*) \neq 0$. $\lrb{x_k}$ 是算法 2.1 产生的序列, 则当 $x_0$ 充分靠近 $x^*$ 时, 有</p><ul><li><p>$\displaystyle\lim_{k \to \infty} x_k = x^*$;</p></li><li><p>$\displaystyle\lim_{k \to \infty} \dfrac{\lrv{x_{k + 1} - x^*}}{\lrv{x_k - x^*}} = 0$;</p></li><li><p>特别地, 若 $f \in C^3$, 则 $\lrv{x_{k + 1} - x^*} = O\left(\lrv{x_k - x^*}^2\right)$.</p></li></ul><p><strong>证明</strong></p><p>\begin{align*}<br>x_{k + 1} - x^* &amp;= x_k - \dfrac{f’(x_k)}{f^{\prime\prime}(x_k)} - x^*\\<br>&amp;= x_k - x^* - \dfrac{f’(x_k)}{f^{\prime\prime}(x_k)}\\<br>&amp;= x_k - x^* - \dfrac{\displaystyle\int_{x^*}^{x_k} f^{\prime\prime}(x)\di x}{f^{\prime\prime}(x_k)}\\<br>&amp;= \dfrac{1}{f^{\prime\prime}(x_k)}\left( \int_{x^*}^{x_k} \left( f^{\prime\prime}(x_k) - f^{\prime\prime}(x) \right) \di x\right),<br>\end{align*}</p><p>因为 $f \in C^2$ 且 $f^{\prime\prime}(x^*) \neq 0$, 所以存在 $\de &gt; 0$, $x, y \in (x^* - \de, x^* + \de)$ 时, 有</p>\begin{equation*}\lrv{f^{\prime\prime}(x) - f^{\prime\prime}(y)} \leqslant \dfrac{1}{2}\lrv{f^{\prime\prime}(x)},\end{equation*}<p>进而</p>\begin{equation*}\lrv{x_{k + 1} - x^*} \leqslant \dfrac{1}{2}\lrv{x_{k} - x^*},\end{equation*}<p>第一个结论得证.<span style="float:right;">$\square$</span></p><p><strong>习题 2.1</strong> 证明定理 2.1 的后两个结论.</p><p><strong>证明</strong> 由 Taylor 公式可得</p>\begin{equation*}0 = f'(x^*) = f'(x_k) + f^{\prime\prime}(x_k)(x^* - x_k) + o(\lrv{x^* - x_k}),\end{equation*}<p>于是</p>\begin{equation*}x_{k + 1} - x^* = x_k - \dfrac{f'(x_k)}{f^{\prime\prime}(x_k)} - x^* = -\dfrac{f'(x_k) + f^{\prime\prime}(x_k)(x^* - x_k)}{f^{\prime\prime}(x_k)} = o(\lrv{x^* - x_k}).\end{equation*}<p>由 Taylor 公式可得</p>\begin{equation*}0 = f'(x^*) = f'(x_k) + f^{\prime\prime}(x_k)(x^* - x_k) + \dfrac{1}{2}f^{\prime\prime\prime}(x_k)(x^* - x_k)^2 + o(\lrv{x^* - x_k}^2),\end{equation*}<p>于是</p>\begin{equation*}0 = \dfrac{f'(x_k)}{f^{\prime\prime}(x_k)} + x^* - x_k + \dfrac{f^{\prime\prime\prime}(x_k)}{2f^{\prime\prime}(x_k)}(x^* - x_k)^2 + o(\lrv{x^* - x_k}^2),\end{equation*}<p>进而</p>\begin{equation*}\dfrac{x_{k + 1} - x^*}{\left(x^* - x_k\right)^2} = \dfrac{f^{\prime\prime\prime}(x_k)}{2f^{\prime\prime}(x_k)} + o(1) = O(1),\end{equation*}<p>故 $\lrv{x_{k + 1} - x^*} = O\left(\lrv{x_k - x^*}^2\right)$.<span style="float:right;">$\square$</span></p><p><strong>定义 2.1</strong> 记 $e_k = \lrvv{x_k - x^*}$, 取</p>\begin{equation*}Q_p := \limsup_{k\to\infty} \dfrac{e_{k + 1}}{e_{k}^p},\quad p > 0.\end{equation*}<ul><li><p>若 $0 &lt; Q_1 &lt; 1$, 则称 $x_k$ 是<strong>线性收敛</strong>的.</p></li><li><p>若 $Q_1 = 0$, 则称 $x_k$ 是<strong>超线性收敛</strong>的.</p></li><li><p>若 $p &gt; 1$ 且 $0 &lt; Q_p &lt; \infty$, 则称 $x_k$ 是 <strong>$p$ 阶收敛</strong>的.</p></li><li><p>Newton 法是超线性收敛的. 若 $f \in C^3$, 则 Newton 法是二阶收敛的.</p></li></ul><p><strong>习题 2.2</strong> 假定 $\lrvv{x_0 - x^*} = 3 \times 10^{-3}$, 设两个算法收敛速度分别为</p>\begin{equation*}\dfrac{\lrvv{x_{k + 1} - x^*}}{\lrvv{x_{k} - x^*}} = \dfrac{1}{2},\quad \dfrac{\lrvv{x_{k + 1} - x^*}}{\lrvv{x_{k} - x^*}^2} = \dfrac{1}{2},\end{equation*}<p>若需要达到 $\lrvv{x_{k} - x^*} \leqslant 10^{-9}$, 则两个算法分别需要多少次迭代?</p><p><strong>解</strong> 对于第一种算法有</p>\begin{equation*}\dfrac{1}{2^k} = \dfrac{\lrvv{x_{k} - x^*}}{\lrvv{x_{0} - x^*}} \leqslant \dfrac{10^{-9}}{3 \times 10^{-3}},\end{equation*}<p>解得 $k \geqslant \log_2 3 \times 10^6 \approx 21.5165$, 至少 $22$ 次迭代.</p><p>对于第二种算法有<br>\begin{align*}<br>\lrvv{x_{1} - x^*} &amp;= \dfrac{1}{2}\lrvv{x_{0} - x^*}^{2} = 4.5 \times 10^{-6} &gt; 10^{-9},\\<br>\lrvv{x_{2} - x^*} &amp;= \dfrac{1}{2}\lrvv{x_{1} - x^*}^{2} = 1.0125 \times 10^{-11} &lt; 10^{-9},<br>\end{align*}</p><p>所以至少 $2$ 次迭代.<span style="float:right;">$\square$</span></p><h1 id="割线法"><a href="#割线法" class="headerlink" title="割线法"></a>割线法</h1><p>割线法的思想和 Newton 法非常相似, 它甚至可以看成是 Newton 法的一种近似. Newton 法的核心是迭代公式</p>\begin{equation*}x_{k + 1} = x_k - \dfrac{f'(x_k)}{f^{\prime\prime}(x_k)},\end{equation*}<p>但实际计算中由于 $f$ 的光滑性或者计算复杂度的问题, 我们经常希望避免二阶导数的计算.</p><p>想法: 用差商来近似 (替代) 求导运算, 即</p>\begin{equation*}f^{\prime\prime}(x_k) \approx \dfrac{f'(x_k) - f'(x_{k - 1})}{x_k - x_{k - 1}},\end{equation*}<p>代入 Newton 法中, 得到</p>\begin{equation*}x_{k + 1} = x_k - \dfrac{f'(x_k)}{\dfrac{f'(x_k) - f'(x_{k - 1})}{x_k - x_{k - 1}}}.\end{equation*}<p><strong>算法 2.2 (一维优化问题割线法)</strong></p><p>Step 1. 给定 $\ep &gt; 0$, 初始值 $x_0$, $x_1$, 令 $k = 1$, 计算 $f’(x_{k - 1})$.</p><p>Step 2. 计算 $f’(x_k)$.</p><p>Step 3. 若 $\lrv{f’(x_k)} &lt; \ep$ 则停止, 输出 $x^* = x_k$, 否则计算</p>\begin{equation*}x_{k + 1} = x_k - \dfrac{f'(x_k)(x_k - x_{k - 1})}{f'(x_k) - f'(x_{k - 1})},\end{equation*}<p>令 $k = k + 1$, 进入 Step 2.</p><p>下面通过数学分析来看割线法的可靠性与有效性.</p><p><strong>定理 2.2</strong> 设 $f \in C^3$, $f’(x^*) = 0$, $f^{\prime\prime}(x^*) \neq 0$, 则当 $x_1$, $x_2$ 充分靠近 $x^*$ 时, 算法 2.2 产生的序列 $\lrb{x_k}$ 满足</p>\begin{equation*}\lim_{k \to \infty} \dfrac{\lrvv{x_{k + 1} - x^*}}{\lrvv{x_{k + 1} - x^*}^\tau} = \lrvv{\dfrac{f^{\prime\prime\prime}(x^*)}{2f^{\prime\prime}(x^*)}}^\frac{1}{\tau},\quad \text{其中}~\tau = \dfrac{\sqrt{5} + 1}{2} < 2.\end{equation*}<p><strong>证明</strong> <span style="color: red"><strong>(这个证明我感觉有问题, 主要是 Peano 余项那部分估计)</strong></span> 作差<br>\begin{align}<br>x_{k + 1} - x^* &amp;= x_k - \dfrac{f’(x_k)(x_k - x_{k - 1})}{f’(x_k) - f’(x_{k - 1})} - x^*\nonumber\\<br>&amp;= \dfrac{1}{f’(x_k) - f’(x_{k - 1})}\left( f’(x_k)(x_{k - 1} - x^*) - f’(x_{k - 1})(x_{k} - x^*) \right),\label{equ:xkp1xs}<br>\end{align}</p><p>由 $f \in C^3$, 利用带 Peano 余项的 Taylor 展开<br>\begin{align*}<br>f’(x_k) &amp;= f’(x^*) + f^{\prime\prime}(x^*)(x_k - x^*) + \dfrac{1}{2}f^{\prime\prime\prime}(x^*)(x_k - x^*)^2 + o\left( \lrv{x_k - x^*}^2 \right),\\<br>f’(x_{k - 1}) &amp;= f’(x^*) + f^{\prime\prime}(x^*)(x_{k - 1} - x^*) + \dfrac{1}{2}f^{\prime\prime\prime}(x^*)(x_{k - 1} - x^*)^2 + o\left( \lrv{x_{k - 1} - x^*}^2 \right),<br>\end{align*}</p><p>代回 \eqref{equ:xkp1xs} 式得 (第一项由于 $f’(x^*) = 0$ 消失, 第二项由于抵消消失)<br>\begin{align}<br>x_{k + 1} - x^* =&amp; \dfrac{1}{f’(x_k) - f’(x_{k - 1})} \left( \dfrac{f^{\prime\prime\prime}(x^*)}{2}(x_k - x^*)(x_{k - 1} - x^*)(x_k - x_{k - 1}) \right)\nonumber\\<br>&amp;+ \dfrac{1}{f’(x_k) - f’(x_{k - 1})} \left( (x_{k - 1} - x^*) o\left( \lrv{x_k - x^*}^2 \right)\right.\nonumber\\<br>&amp;\quad\quad\quad\quad\quad\quad\quad\quad\quad -\left. (x_k - x^*) o\left( \lrv{x_{k - 1} - x^*}^2 \right) \right)\nonumber\\<br>=&amp;: T_1 + T_2\quad (\text{两项分别记为}~T_1~\text{与}~T_2).\label{equ:T1T2}<br>\end{align}</p><p>对于 $T_1$, 由中值定理可得</p>\begin{equation*}f'(x_k) - f'(x_{k - 1}) = \left( f^{\prime\prime}(x^*) + o(1) \right)(x_k - x_{k - 1}),\end{equation*}<p>代入可得</p>\begin{equation*}T_1 = \dfrac{f^{\prime\prime\prime}(x^*)}{2}(x_k - x^*)(x_{k - 1} - x^*)\dfrac{1}{f^{\prime\prime}(x^*) + o(1)}.\end{equation*}<p>由</p>\begin{equation*}\dfrac{1}{f^{\prime\prime}(x^*)} - \dfrac{1}{f^{\prime\prime}(x^*) + o(1)} = \dfrac{o(1)}{f^{\prime\prime}(x^*)\left( f^{\prime\prime}(x^*) + o(1) \right)}\end{equation*}<p>有</p>\begin{equation*}T_1 = \dfrac{f^{\prime\prime\prime}(x^*)}{2f^{\prime\prime}(x^*)}(x_k - x^*)(x_{k - 1} - x^*) + o\left( \lrv{x_k - x^*}\lrv{x_{k - 1} - x^*} \right).\end{equation*}<p>对于 $T_2$, 记 $e_k = x_k - x^*$, $r_k = r(e_k)$ 为 Peano 余项, 它是 $e_k$ 的函数, 有<br>\begin{equation}\label{equ:rxx2}<br>\displaystyle\lim_{x \to 0}\dfrac{r(x)}{x^2} = 0,<br>\end{equation}</p><p>及<br>\begin{align*}<br>T_2 &amp;= \dfrac{1}{f’(x_k) - f’(x_{k - 1})}\left( e_{k - 1}r_k - e_kr_{k - 1} \right)\\<br>&amp;= \dfrac{1}{f^{\prime\prime}(\tilde{x})(x_k - x_{k - 1})} e_{k - 1}e_k\left( \dfrac{r_k}{e_k} - \dfrac{r_{k - 1}}{e_{k - 1}} \right)\quad \text{其中}~\tilde{x} \in (x_{k - 1}, x_k)\\<br>&amp;= \dfrac{1}{f^{\prime\prime}(\tilde{x})}\dfrac{e_{k - 1}e_k}{e_k - e_{k - 1}}\left( \dfrac{r_k}{e_k} - \dfrac{r_{k - 1}}{e_{k - 1}} \right).<br>\end{align*}</p><p>记 $g(x) = \dfrac{r(x)}{x}$, 由 \eqref{equ:rxx2} 式可得 $\displaystyle\lim_{x \to 0} g’(x) = 0$, 于是<br>\begin{align*}<br>\lim_{k \to \infty}\dfrac{T_2}{e_ke_{k - 1}} &amp;= \lim_{k \to \infty} \dfrac{1}{f^{\prime\prime}(\tilde{x})} \dfrac{1}{e_k - e_{k - 1}}\left( \dfrac{r_k}{e_k} - \dfrac{r_{k - 1}}{e_{k - 1}} \right)\\<br>&amp;= \lim_{k \to \infty} \dfrac{1}{f^{\prime\prime}(\tilde{x})} \dfrac{1}{e_k - e_{k - 1}} g’(\tilde{e})\left( e_k - e_{k - 1}\right)\quad \text{其中}~\tilde{e} \in (e_{k - 1}, e_k)\\<br>&amp; = 0.<br>\end{align*}</p><p>故 $T_2 = o(e_k e_{k - 1})$. 由 \eqref{equ:T1T2} 式结合 $T_1$ 与 $T_2$ 的估计可得</p>\begin{equation*}x_{k + 1} - x^* = \dfrac{f^{\prime\prime\prime}(x^*)}{2f^{\prime\prime}(x^*)}(x_k - x^*)(x_{k - 1} - x^*) + o\left( \lrv{x_k - x^*}\lrv{x_{k - 1} - x^*} \right),\end{equation*}<p>所以 $x_k \to x^*$, $k \to \infty$, 进而使用以下引理即可证得定理结论.<span style="float:right;">$\square$</span></p><p><strong>引理 2.1</strong> 设 $e_k &gt; 0$ 且 $\displaystyle\lim_{k \to \infty} e_k = 0$, 若 $e_{k + 1} = \beta_k e_k e_{k - 1}$, 其中 $\beta_k \to \beta^* &gt; 0$, 则</p>\begin{equation*}\lim_{k \to \infty} \dfrac{e_{k + 1}}{e_k^\tau} = \left(\beta^* \right)^\frac{1}{\tau},\quad \tau = \dfrac{\sqrt{5} + 1}{2}.\end{equation*}<p><strong>习题 2.3</strong> 证明上述引理. 提示: $\ln e_{k + 1} = \ln e_k + \ln e_{k - 1} + \ln \beta_k$, 利用 $\tau^2 = \tau + 1$, 有</p>\begin{equation*}\ln e_{k + 1} - \tau \ln e_k = -\dfrac{1}{\tau} \left( \ln e_k - \tau \ln e_{k - 1} \right) + \ln \beta_k.\end{equation*}<p><strong>证明</strong> 利用提示内容, 有</p>\begin{equation*}\ln e_{k + 1} - \tau \ln e_k - \dfrac{1}{\tau}\ln\ba_k = -\dfrac{1}{\tau} \left( \ln e_k - \tau \ln e_{k - 1} - \dfrac{1}{\tau}\ln\ba_{k - 1} \right) + \dfrac{\ln \beta_k - \ln \ba_{k - 1}}{\tau^2}.\end{equation*}<p>令</p>\begin{equation*}a_k = \ln e_{k + 1} - \tau \ln e_k - \dfrac{1}{\tau}\ln\ba_k,\quad b_{k - 1} = \dfrac{\ln \beta_{k} - \ln \ba_{k - 1}}{\tau^2},\end{equation*}<p>有<br>\begin{align*}<br>a_k &amp;= -\dfrac{1}{\tau}a_{k - 1} + b_{k - 1}\\<br>&amp;= -\dfrac{1}{\tau}\left( -\dfrac{1}{\tau}a_{k - 2} + b_{k - 2} \right) + b_{k - 1}\\<br>&amp;=\dfrac{a_1}{(-\tau)^{k - 1}} + \left( b_{k - 1} - \dfrac{1}{\tau}b_{k - 2} + \dfrac{1}{\tau^2}b_{k - 3} + \cdots + \dfrac{1}{(-\tau)^{k - 2}}b_{1} \right)\\<br>&amp;=: x_{k - 1} + y_{k - 1}.<br>\end{align*}</p><p>由 $\displaystyle\lim_{k \to \infty} b_k = 0$, 对于任意 $\ep &gt; 0$, 存在 $N \in \N$, $n &gt; N$ 时, $\lrv{b_k} &lt; \ep$. 令 $M = \lrb{\lrv{b_1}, \lrv{b_2}, \cdots, \lrv{b_N}}$, 有<br>\begin{align*}<br>\lrv{y_{k - 1}} &amp;= \lrv{b_{k - 1} - \dfrac{1}{\tau}b_{k - 2} + \cdots + \dfrac{1}{(-\tau)^{k - 1 - N}}b_N + \cdots + \dfrac{1}{(-\tau)^{k - 2}}b_{1}}\\<br>&amp;\leqslant \left( 1 + \dfrac{1}{\tau} + \cdots + \dfrac{1}{\tau^{k - 1 - N}} \right)\ep + \left( \dfrac{1}{\tau^{k - N}} + \cdots + \dfrac{1}{\tau^{k - 2}} \right) M\\<br>&amp;&lt; \left( \sum_{i = 0}^{\infty} \dfrac{1}{\tau^i} \right)\ep + \left( \sum_{i = k - N}^{\infty} \dfrac{1}{\tau^i} \right)M\\<br>&amp;= \dfrac{1}{1 + \tau}\ep + \left( \sum_{i = k - N}^{\infty} \dfrac{1}{\tau^i} \right)M,<br>\end{align*}</p><p>令 $k \to \infty$, 有</p>\begin{equation*}\lim_{k \to \infty} \lrv{y_{k - 1}} < \dfrac{1}{1 + \tau}\ep,\end{equation*}<p>由 $\ep$ 的任意性知 $\displaystyle\lim_{k \to \infty} y_{k - 1} = 0$. 显然有 $\displaystyle\lim_{k \to \infty} x_{k - 1} = 0$, 因此 $\displaystyle\lim_{k \to \infty} a_{k} = 0$, 进而有</p>\begin{equation*}\lim_{k \to \infty} \ln e_{k + 1} - \tau \ln e_k = \lim_{k \to \infty} \dfrac{1}{\tau}\ln\ba_k = \dfrac{1}{\tau} \ln \ba^*,\end{equation*}<p>所以<br>\begin{align*}<br>\lim_{k \to \infty} \dfrac{e_{k + 1}}{e_k^\tau} = \left(\beta^* \right)^\frac{1}{\tau}.\tag*{$\square$}<br>\end{align*}</p><h1 id="两种方法统一的刻画"><a href="#两种方法统一的刻画" class="headerlink" title="两种方法统一的刻画"></a>两种方法统一的刻画</h1><p>前面两种方法都可以用以下的方式刻画.</p><p>考虑 \eqref{equ:fpxEqu0} 式, 要得到 $x^*$, 从 $x_k$ 出发, 构造一个线性函数 $\eta_k(x)$ 逼近 $f’(x)$, 然后求解 $\eta_k(x_{k + 1}) = 0$, 得到近似值 $x^* = x_{k + 1}$.</p><p>回到 \eqref{equ:notResOneOpt} 式上, 同样地从 $x_k$ 出发, 构造一个二次函数 $\p_k(x)$ 逼近 $f(x)$, 然后求解 $\displaystyle\min_{x \in \R} \p_k(x)$ 的极小 $x_{k + 1}$, 得到近似值 $x^* = x_{k + 1}$.</p><p>前面所述的两种方法构造的二次函数为<br>\begin{equation}\label{equ:pkx}<br>\p_k(x) = f(x_k) + f’(x_k)(x - x_k) + \dfrac{1}{2} c_k(x - x_k)^2,<br>\end{equation}</p><p>满足条件</p>\begin{equation*}\p_k(x_k) = f(x_k),\quad \p'_k(x_k) = f'(x_k),\end{equation*}<p>要求出 $c_k$ 还需要增加条件.</p><p>对于 Newton 方法, 增加的条件为 $\p_k^{\prime\prime}(x_k) = f^{\prime\prime}(x_k)$, 解得 $c_k = f^{\prime\prime}(x_k)$, 进而 $x_{k + 1} = x_k - \dfrac{f’(x_k)}{f^{\prime\prime}(x_k)}$.</p><p>对于割线法, 增加的条件为 $\p’_k(x_{k - 1}) = f’(x_{k - 1})$, 解得 $c_k = \dfrac{f’(x_k) - f’(x_{k - 1})}{x_k - x_{k - 1}}$, 进而 $x_{k + 1} = x_k - \dfrac{f’(x_k)(x_k - x_{k - 1})}{f’(x_k) - f’(x_{k - 1})}$.</p><p><strong>习题 2.4</strong> 若增加的条件为 $\p_k(x_{k - 1}) = f(x_{k - 1})$, 计算 $c_k$, 并进一步写出算法的迭代公式.</p><p>将 $\p_k(x_{k - 1}) = f(x_{k - 1})$ 代入 \eqref{equ:pkx} 式, 解得</p>\begin{equation*}c_k = \dfrac{2\left( f(x_{k - 1}) - f(x_k) -f'(x_k)(x_{k - 1} - x_k)\right)}{(x_{k - 1} - x_k)^2}.\end{equation*}<p>$\p_k(x)$ 的极小值点满足</p>\begin{equation*}x - x_k = -\dfrac{f'(x_k)} {c_k},\end{equation*}<p>故迭代公式为<br>\begin{align*}<br>x_{k + 1} = x_k - \dfrac{f’(x_k)(x_{k - 1} - x_k)^2}{2\left( f(x_{k - 1}) - f(x_k) -f’(x_k)(x_{k - 1} - x_k)\right)}.\tag*{$\square$}<br>\end{align*}</p><p><strong>程序 1</strong> 求解 $\displaystyle\min_{x \in \R} -x\e^{-x}$, 已知 $x^* = 1$, 编制 Newton 法和割线法的程序来求解并进行比较, 初值选取为:</p><ul><li>Newton 法: $x_0 = 0$;</li><li>割线法: $x_0 = 0$, $x_1 = 0.5$.</li></ul><p><strong>解</strong> 取 $\ep = 2^{-52}$ (即 MATLAB 的浮点相对精度), 代码如下.</p><pre><code class="lang-MATLAB">clear, clc, close all;syms xf(x) = -x .* exp(-x);x0 = 0;x1 = 0.5;varepsilon = eps;df = diff(f);ddf = diff(df);%% Newton 法x = x0;while true    xk = x(end);    x = [x; double(xk - df(xk) ./ ddf(xk))];    if abs(df(x(end))) &lt; varepsilon        break;    endend%% 割线法y = [x0; x1];while true    xk = y(end);    dfxk = df(xk);    if abs(dfxk) &lt; varepsilon        break;    end    y = [y; double(xk - dfxk .* (xk - y(end - 1)) ./ (dfxk - df(y(end - 1))))];end%% 比较figure;plot(0 : (size(x, 1) - 1), abs(1 - x), 0 : (size(y, 1) - 1), abs(1 - y)), ...    xlabel(&#39;迭代次数&#39;, &#39;FontName&#39;, &#39;微软雅黑&#39;), ...    ylabel(&#39;误差&#39;, &#39;FontName&#39;, &#39;微软雅黑&#39;), ...    legend(&#39;Newton 法&#39;, &#39;割线法&#39;, &#39;FontName&#39;, &#39;微软雅黑&#39;);format long;disp(x);disp(x - 1);disp(abs(x(2 : end) - 1) ./ abs(x(1 : (end - 1)) - 1) .^ 2);disp(y);disp(y - 1);disp(abs(y(2 : end) - 1) ./ abs(y(1 : (end - 1)) - 1) .^ ((sqrt(5) + 1) ./ 2));</code></pre><p>运行结果如下. 注意到 Newton 法的 $\dfrac{\lrv{x_k - x^*}}{\lrv{x_{k - 1} - x^*}^2}$ 与割线法的 $\dfrac{\lrv{x_k - x^*}}{\lrv{x_{k - 1} - x^*}^\tau}$ 都趋近于 $\lrv{\dfrac{f^{\prime\prime\prime}(x^*)}{2f^{\prime\prime}(x^*)}} = 1$.</p><p><img src="/img/OptimizationTheory/Program1.svg" srcset="/img/loading.gif" title="两种方法的误差比较" alt="两种方法的误差比较"></p><style>table {    display: table!important;}</style><div style="text-align:center">Newton 法</div><div class="table-container"><table><thead><tr><th style="text-align:center">$x_k$</th><th style="text-align:center">$x_k - x^*$</th><th style="text-align:center">$\dfrac{\lrv{x_k - x^*}}{\lrv{x_{k - 1} - x^*}^2}$</th></tr></thead><tbody><tr><td style="text-align:center">$0$</td><td style="text-align:center">$-1.000000000000000$</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">$0.500000000000000$</td><td style="text-align:center">$-0.500000000000000$</td><td style="text-align:center">$0.500000000000000$</td></tr><tr><td style="text-align:center">$0.833333333333333$</td><td style="text-align:center">$-0.166666666666667$</td><td style="text-align:center">$0.666666666666667$</td></tr><tr><td style="text-align:center">$0.976190476190476$</td><td style="text-align:center">$-0.023809523809524$</td><td style="text-align:center">$0.857142857142858$</td></tr><tr><td style="text-align:center">$0.999446290143965$</td><td style="text-align:center">$-0.000553709856035$</td><td style="text-align:center">$0.976744186046483$</td></tr><tr><td style="text-align:center">$0.999999693575066$</td><td style="text-align:center">$-0.000000306424934$</td><td style="text-align:center">$0.999446596698782$</td></tr><tr><td style="text-align:center">$0.999999999999906$</td><td style="text-align:center">$-0.000000000000094$</td><td style="text-align:center">$1.000304885275709$</td></tr><tr><td style="text-align:center">$1.000000000000000$</td><td style="text-align:center">$0$</td><td style="text-align:center">$0$</td></tr></tbody></table></div><p><br></p><div style="text-align:center">割线法</div><div class="table-container"><table><thead><tr><th style="text-align:center">$x_k$</th><th style="text-align:center">$x_k - x^*$</th><th style="text-align:center">$\dfrac{\lrv{x_k - x^*}}{\lrv{x_{k - 1} - x^*}^\tau}$</th></tr></thead><tbody><tr><td style="text-align:center">$0$</td><td style="text-align:center">$-1.000000000000000$</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">$0.500000000000000$</td><td style="text-align:center">$-0.500000000000000$</td><td style="text-align:center">$0.500000000000000$</td></tr><tr><td style="text-align:center">$0.717633299196792$</td><td style="text-align:center">$-0.282366700803208$</td><td style="text-align:center">$0.866742802928595$</td></tr><tr><td style="text-align:center">$0.898802528965495$</td><td style="text-align:center">$-0.101197471034505$</td><td style="text-align:center">$0.783018667120379$</td></tr><tr><td style="text-align:center">$0.976078343656424$</td><td style="text-align:center">$-0.023921656343576$</td><td style="text-align:center">$0.973779328626748$</td></tr><tr><td style="text-align:center">$0.997722783634153$</td><td style="text-align:center">$-0.002277216365847$</td><td style="text-align:center">$0.956258176135382$</td></tr><tr><td style="text-align:center">$0.999946231646904$</td><td style="text-align:center">$-0.000053768353096$</td><td style="text-align:center">$1.014697058670582$</td></tr><tr><td style="text-align:center">$0.999999877700416$</td><td style="text-align:center">$-0.000000122299584$</td><td style="text-align:center">$0.989869260031477$</td></tr><tr><td style="text-align:center">$0.999999999993424$</td><td style="text-align:center">$-0.000000000006576$</td><td style="text-align:center">$1.006279510682946$</td></tr><tr><td style="text-align:center">$1.000000000000000$</td><td style="text-align:center">$0$</td><td style="text-align:center">$0$</td></tr></tbody></table></div><h1 id="抛物线法"><a href="#抛物线法" class="headerlink" title="抛物线法"></a>抛物线法</h1><p>若 $\p_k(x) = ax^2 + bx + c$ 满足</p><p>\begin{equation}\begin{cases}\begin{aligned}<br>\p_k(x_k) &amp;= f(x_k),\\<br>\p_k(x_{k - 1}) &amp;= f(x_{k - 1}),\\<br>\p_k(x_{k - 2}) &amp;= f(x_{k - 2}),<br>\end{aligned}\end{cases}\label{equ:kk-1k-2}\end{equation}</p><p>则可以求出 $x_{k + 1} = \underset{x \in \R}{\mathrm{argmin}} \p_k(x)$ 来逼近 $x^*$.</p><p>为了求解 \eqref{equ:kk-1k-2} 式, 可以利用 Lagrange 插值公式, 有</p><p>\begin{align*}<br>\p_k(x) &amp;= f(x_{k - 2}) \dfrac{(x - x_{k - 1})(x - x_k)}{(x_{k - 2} - x_{k - 1})(x_{k - 2} - x_k)}\\<br>&amp;\quad + f(x_{k - 1}) \dfrac{(x - x_{k - 2})(x - x_k)}{(x_{k - 1} - x_{k - 2})(x_{k - 1} - x_k)}\\<br>&amp;\quad + f(x_{k}) \dfrac{(x - x_{k - 1})(x - x_{k - 2})}{(x_{k} - x_{k - 1})(x_{k} - x_{k - 2})}<br>\end{align*}</p><p><strong>习题 2.5</strong> 写出抛物线法的迭代公式, 进一步写出相应的算法. 注意:</p><ul><li>每个迭代步只需算一次函数值;</li><li>如何选点进入新的迭代.</li></ul><p><strong>解</strong> Lagrange 插值得到的公式为<br>\begin{align*}<br>\p_k(x) &amp;= \dfrac{f(x_{k - 2})(x_k - x_{k - 1}) + f(x_{k - 1})(x_{k - 2} - x_k) + f(x_{k})(x_{k - 1} - x_{k - 2})}{(x_{k - 2} - x_{k - 1})(x_{k - 1} - x_k)(x_k - x_{k - 2})} x^2\\<br>&amp;\quad + \dfrac{f(x_{k - 2})(x_{k - 1}^2 - x_k^2) + f(x_{k - 1})(x_k^2 - x_{k - 2}^2) + f(x_{k})(x_{k - 2}^2 - x_{k - 1}^2)}{(x_{k - 2} - x_{k - 1})(x_{k - 1} - x_k)(x_k - x_{k - 2})} x + c,<br>\end{align*}<br>最小值点即迭代公式为<br>\begin{equation}\label{equ:xkp1}<br>x_{k + 1} = \dfrac{f(x_{k - 2})(x_{k - 1}^2 - x_k^2) + f(x_{k - 1})(x_k^2 - x_{k - 2}^2) + f(x_{k})(x_{k - 2}^2 - x_{k - 1}^2)}{2(f(x_{k - 2})(x_{k - 1} - x_k) + f(x_{k - 1})(x_k - x_{k - 2}) + f(x_{k})(x_{k - 2} - x_{k - 1}))}.<br>\end{equation}<br>具体算法如下.</p><p>Step 1. 给定 $\ep &gt; 0$, 初始值 $x_0 &lt; x_1 &lt; x_2$, 使得 $f(x_1) &lt; f(x_0)$, $f(x_1) &lt; f(x_2)$ (可用进退法确定: 给定 $x_0$, 步长 $h$, $\lambda = 1$, 若 $f(x_0) &gt; f(x_1)$, 则 $x_2 = x_1 + \lambda h$, 不断扩大 $\lambda$ 使得 $f(x_2) &gt; f(x_1)$, 若 $f(x_0) \leqslant f(x_1)$, 则 $x_2 = x_1 - \lambda h$, 不断扩大 $\lambda$ 使得 $f(x_2) &gt; f(x_0)$).</p><p>Step 2. 若 $\lrv{x_2 - x_0} &lt; \ep$, 则停止, 输出 $x^* = x_1$, 否则进入 Step 3.</p><p>Step 3. 利用 \eqref{equ:xkp1} 式计算 $x_3$, 若 $f(x_3) &lt; f(x_1)$, 则进入 Step 4, 否则进入 Step 5.</p><p>Step 4. 若 $x_3 &lt; x_1$, 则令 $x_2 = x_1$, 否则令 $x_0 = x_1$. 然后令 $x_1 = x_3$, 进入 Step 2.</p><p>Step 5. 若 $x_3 &lt; x_1$ 则令 $x_0 = x_3$, 否则令 $x_2 = x_3$. 然后进入 Step 2.<span style="float:right;">$\square$</span></p><h1 id="二分法"><a href="#二分法" class="headerlink" title="二分法"></a>二分法</h1><p>要求解 $f’(x^*) = 0$, 可以通过迭代试探点来分割并缩小搜索区间, 目标:</p><ul><li>极小点始终在搜索区间内;</li><li>区间缩小的速率尽可能快.</li></ul><p><strong>定理 2.3 (根存在定理)</strong> 若 $f’(a)f’(b) &lt; 0$, 则 $f’(x) = 0$ 在 $(a, b)$ 内一定存在根.</p><p>根据定理 2.3, 选取区间的办法如下.</p><ul><li>若 $f’(a)f’(c) &lt; 0$, 则选取 $[a’, b’] = [a, c]$.</li><li>若 $f’(b)f’(c) &lt; 0$, 则选取 $[a’, b’] = [c, b]$.</li></ul><p>考虑最坏的情况, 有</p>\begin{equation*}\min\dfrac{\lrv{a' - b'}}{\lrv{a - b}} = \min_{c \in (a, b)}\dfrac{\max \lrb{\lrv{a - c}, \lrv{b - c}}}{\lrv{a - b}} = \dfrac{1}{2},\end{equation*}<p>即选取 $c = \dfrac{1}{2}(a + b)$ 可使收敛速度最快, 此时每次区间缩小到原来的 $\dfrac{1}{2}$, 为线性收敛的算法.</p><p><strong>练习</strong> 写出二分法的算法.</p><h1 id="Fibonacci-法"><a href="#Fibonacci-法" class="headerlink" title="Fibonacci 法"></a>Fibonacci 法</h1><p>首先定义一个区间上的单峰函数.</p><p><strong>定义 2.2 (单峰函数)</strong> $f \in C([a, b])$, 若 $x^* \in [a, b]$ 使得 $f$ 在 $[a, x^*]$ 上严格单调下降, 在 $[x^*, b]$ 上严格单调上升, 则称 $f$ 是 $[a, b]$ 上的单峰函数.</p><p>有如下性质.</p><ol><li><p>$x^*$ 是 $f$ 在 $[a, b]$ 上的极小值点.</p></li><li><ul><li><p>若 $a’ \in [a, x^*]$, 则 $f$ 在 $[a’, b]$ 上是单峰函数;</p></li><li><p>若 $b’ \in [x^*, b]$, 则 $f$ 在 $[a, b’]$ 上是单峰函数.</p></li></ul></li><li><p>设 $x_1, x_2 \in [a, b]$, $x_1 &lt; x_2$.</p><ul><li><p>若 $f(x_1) &lt; f(x_2)$, 则 $x^* \in [a, x_2]$.</p></li><li><p>若 $f(x_1) &gt; f(x_2)$, 则 $x^* \in [x_1, b]$.</p></li><li><p>若 $f(x_1) &lt; f(x_2)$, 则 $x^* \in [x_1, x_2]$.</p></li></ul></li></ol><p>利用性质 3, 可以将 $[a, b]$ 缩小为 $[a’, b’]$:</p>\begin{equation*}[a', b'] = \left\{\begin{array}{ll}[a, x_2],    &    \text{若}~f(x_1) < f(x_2),\\[x_1, b],    &    \text{若}~f(x_1) > f(x_2),\\[x_1, x_2],    &    \text{若}~f(x_1) = f(x_2).\end{array}\right.\end{equation*}<p>如何寻找试探点 $x_1$, $x_2$, 使得 $\dfrac{\lrv{a’ - b’}}{\lrv{a - b}}$ 尽可能地小?</p><p><strong><div style="color:red">(后面再补)</div></strong></p><p><strong>习题 2.6</strong> 写出完整的 Fibonacci 算法. 提示:</p><ul><li>由 $\ep$ 来决定迭代次数 $k$;</li><li>每一步只计算一次函数值.</li></ul><p><strong>解</strong></p><p>Step 1. 给定 $[a, b]$ 和 $\ep &gt; 0$, 求得 $k$ 及数列 $\lrb{F_i}_{i = 1}^k$ 使得 $F_k \geqslant \dfrac{b - a}{\ep} &gt; F_{k - 1}$.</p><p>令</p>\begin{equation*}x_1 = a + \dfrac{F_{k - 2}}{F_k}(b - a),\quad x_2 = a + \dfrac{F_{k - 1}}{F_k}(b - a),\quad n = 1,\quad f_1 = f(x_1),\quad f_2 = f(x_2).\end{equation*}<p>Step 2. 若 $f_1 &lt; f_2$, 进入 Step 3. 若 $f_1 \geqslant f_2$, 进入 Step 4.</p><p>Step 3. 令</p>\begin{equation*}b = x_2,\quad x_2 = x_1,\quad x_1 = a + \dfrac{F_{k - 2 - n}}{F_{k - n}}(b - a),\quad f_2 = f_1,\quad f_1 = f(x_1),\end{equation*}<p>若 $n = k - 2$ 则停止, 最小值位于 $[a, b]$, 否则 $n = n + 1$, 进入 Step 2.</p><p>Step 4. 令</p>\begin{equation*}a = x_1,\quad x_1 = x_2,\quad x_2 = a + \dfrac{F_{k - 1 - n}}{F_{k - n}}(b - a),\quad f_1 = f_2,\quad f_2 = f(x_2),\end{equation*}<p>若 $n = k - 2$ 则停止, 最小值位于 $[a, b]$, 否则 $n = n + 1$, 进入 Step 2.<span style="float:right;">$\square$</span></p><ul><li><p>优点: 收敛快.</p></li><li><p>缺点: 不灵活, 当精度要求改变时, 需要重新开始算法.</p></li></ul><p>为了克服该缺点, 在 Fibonacci 法的基础上改进出黄金分割法.</p><h1 id="黄金分割法"><a href="#黄金分割法" class="headerlink" title="黄金分割法"></a>黄金分割法</h1><p>目标: 每一步区间缩小的比例相同.</p><p><strong><div style="color:red">(后面再补)</div></strong></p><p>经过 $k$ 步以后 $\a \geqslant \dfrac{1}{F_{k + 1}} \geqslant \a^{k + 1}$, 所以只需要多迭代一步, 算法精度就可以超过 Fibonacci 法, 同时算法更灵活.</p><p><strong>习题 2.7</strong> 证明 $\a^k \geqslant \dfrac{1}{F_{k + 1}} \geqslant \a^{k + 1}$. 提示: 利用 Fibonacci 数列的通项公式.</p><p><strong>证明</strong> 首先求出 Fibonacci 数列的通项公式. 设 $r$, $s$ 满足</p>\begin{equation*}F_k - rF_{k - 1} = s(F_{k - 1} - rF_{k - 2}),\end{equation*}<p>则 $r + s = 1$, $rs = -1$, 解得</p>\begin{equation*}s = \dfrac{1 + \sqrt{5}}{2},\quad r = \dfrac{1 - \sqrt{5}}{2}.\end{equation*}<p>$k \geqslant 2$ 时, 有</p>\begin{equation*}F_k - rF_{k - 1} = s^{k - 1}(F_{1} - rF_{0}) = s^{k - 1} = s^k,\end{equation*}<p>进而<br>\begin{align*}<br>F_k &amp;= rF_{k - 1} + s^k\\<br>&amp;= s^k + rs^{k - 1} + r^2F_{k - 2}\\<br>&amp;= \sum_{i = 0}^k s^{k - i}r^i\\<br>&amp;= \dfrac{s^{k + 1} - r^{k + 1}}{s - r}\\<br>&amp;= \dfrac{1}{\sqrt{5}}\left(\left(\dfrac{1 + \sqrt{5}}{2}\right)^{k + 1} - \left(\dfrac{1 - \sqrt{5}}{2}\right)^{k + 1}\right)\\<br>&amp;= \dfrac{1}{\sqrt{5}}\left(\left(\dfrac{1}{\a}\right)^{k + 1} - \left(-\a\right)^{k + 1}\right),<br>\end{align*}</p><p>代入 $k = 0, 1$ 均成立. 于是<br>\begin{align*}<br>&amp;\a^k \geqslant \dfrac{1}{F_{k + 1}} \geqslant \a^{k + 1}\\<br>\Longleftrightarrow\quad &amp; \a^{-k} \leqslant \dfrac{1}{\sqrt{5}}\left(\left(\dfrac{1}{\a}\right)^{k + 2} - \left(-\a\right)^{k + 2}\right) \leqslant \a^{-k - 1}\\<br>\Longleftrightarrow\quad &amp; \sqrt{5}\a^2 \leqslant 1 - (-\a^2)^{k + 2} \leqslant \sqrt{5} \a,<br>\end{align*}</p><p>上述不等式中只有中间部分是与 $k$ 有关的, 两边都是常数, 故只需分析中间部分的极值. $k$ 为偶数时, $k = 0$ 时取得最小值, 有 $1 - \a^4 = \sqrt{5}\a^2$, 中间部分随 $k$ 的增大而增大, $k \to \infty$ 时, 有 $1 \leqslant \sqrt{5}\a$. $k$ 为奇数时, $k = 1$ 时取得最大值, 有 $1 + \a^6 \leqslant 1.0558 \leqslant 1.3819 \leqslant \sqrt{5}\a$, 中间部分随 $k$ 的增大而减小, $k \to \infty$ 时, 有 $1 \geqslant \sqrt{5}\a^2$.<span style="float:right;">$\square$</span></p><p>练习: 写出黄金分割法的完整算法.</p><h1 id="线搜索"><a href="#线搜索" class="headerlink" title="线搜索"></a>线搜索</h1>]]></content>
    
    
    <categories>
      
      <category>Optimization Theory</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Optimization Theory</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>最优化问题</title>
    <link href="/2020/02/OptimizationTheory1/"/>
    <url>/2020/02/OptimizationTheory1/</url>
    
    <content type="html"><![CDATA[<p>本文基本上是老师的讲义, 少部分为自己理解或修改.</p><h1 id="求最小-大-值问题"><a href="#求最小-大-值问题" class="headerlink" title="求最小 (大) 值问题"></a>求最小 (大) 值问题</h1><p>\begin{equation}\label{equ:OptPro}<br>    \min_{x \in \R^n} f(x),\quad \underset{\text{(subject to)}}{\st} x \in X.<br>\end{equation}</p><p>其中:</p><ul><li>$n$: 维数;</li><li>$x$: $x = (x_1, x_2, \cdots, x_n) \in \R^n$ 为 (优化) 变量;</li><li>$f$: $\R^n \to \R$ 单值函数, 为目标 (函数);</li><li>$X$: $X \subset \R^n$ 为约束集 / 可行域.</li></ul><p>若 $X = \R^n$, 问题 \eqref{equ:OptPro} 变成了 $\displaystyle\min_{x \in \R^n} f(x)$ 称为无约束优化问题.</p><p>若 $X \subsetneq \R^n$, 则称为约束优化问题.</p><p>在很多情况下, 可以用一系列等式和不等式来约束:</p>\begin{equation*}x \in X \Longleftrightarrow \left\{\begin{array}{ll}c_i(x) = 0,    &    i = 1, \cdots, m,\\c_j(x) \geqslant 0,    &    j = 1, \cdots, n.\end{array}\right.\end{equation*}<p>在上述情况下, 问题 \eqref{equ:OptPro} 可以写成如下形式.</p>\begin{equation*}\min_{x \in \R^n} f(x),\quad \st \quad \begin{array}{ll}c_i(x) = 0,    &    i = 1, \cdots, m,\\c_j(x) \geqslant 0,    &    j = 1, \cdots, n.\end{array}\end{equation*}<ul><li>若要求最大值, 可以将其化为最小值.</li></ul>\begin{equation*}\max_{x \in \R^n} f(x),\quad \st x \in X \quad \Longleftrightarrow \quad \min_{x \in \R^n} -f(x),\quad \st x \in X.\end{equation*}<ul><li><p>问题求解的复杂度取决于:</p><ul><li><p>$n$ 的大小, 指数倍增长;</p></li><li><p>$f$ 与 $X(c_i, c_j)$ 的形式.</p></li></ul></li><li><p>为什么关心优化问题的求解, 因为优化问题很重要, People optimize &amp; Nature optimize. 比如说投资风险最小, 收益最大. 物理化学中希望出现在能量最小状态或熵最小状态.</p></li></ul><h1 id="一些例子"><a href="#一些例子" class="headerlink" title="一些例子"></a>一些例子</h1><h2 id="求解线性方程组"><a href="#求解线性方程组" class="headerlink" title="求解线性方程组"></a>求解线性方程组</h2>\begin{equation*}Ax = b,\end{equation*}<p>其中 $A \in \R^{n \times n}$ 为对称正定矩阵, 求解 $x \in \R^n$. 在线性代数中已知</p>\begin{equation*}x = A^{-1}b = \dfrac{1}{\lrv{A}A^* b}.\end{equation*}<p>但实际问题中 $n$ 的数量级为 $10^6 \sim 10^{10}$, $\lrv{A}$ 的算法复杂度为 $O(n!)$, 运算量极大, 需要转化为最优化问题.</p><p>构造</p>\begin{equation*}f : \R^n \to \R, \quad x \mapsto \dfrac{1}{2}x^\T Ax - b^\T x.\end{equation*}<p>结论: 若 $x^* \in \R^n$ 是 $\displaystyle\min_{x \in \R^n} f(x)$ 的解, 则 $Ax^* = b$.</p><p><strong>证明</strong></p>\begin{equation*}0 = \nabla f(x^*) = \left(\left.\dfrac{\pa f(x)}{\pa x_1}\right|_{x = x^* }, \cdots, \left.\dfrac{\pa f(x)}{\pa x_n}\right|_{x = x^* } \right),\end{equation*}<p>其中</p>\begin{equation*}\left.\dfrac{\pa f(x)}{\pa x_i}\right|_{x = x^* } = \dfrac{1}{2}\left(Ax^* \right)_i + \dfrac{1}{2}\left(x^{* \T} A\right)_i - b_i = \left( Ax^* \right)_i - b_i = 0,\end{equation*}<p>于是 $\left( Ax^* \right)_i = b_i$, $i = 1, \cdots, n$, 进而 $Ax^* = b$.<span style="float:right;">$\square$</span></p><p><strong>习题 1.1</strong> 已知 $Ax = \lambda x$, $\lambda \in \R$, $A \in \R^{n \times n}$ 对称正定, 想求 $A$ 的最小特征值 $\lambda_1$, 构造一个最优化问题与之相对应.</p><p><strong>解</strong> 设</p>\begin{equation*}f(x) = \frac{x^\T Ax}{x^\T x},\quad x \in \R^n \setminus \lrb{0},\end{equation*}<p>则 $f$ 的最小值为 $A$ 的最小特征值. 下面证明这个结论.</p><p>因为 $A$ 是实对称矩阵, 所以存在正交矩阵 $P$, 使得 $P^\T AP$ 是对角矩阵. 记该对角矩阵的主对角线上的元素为 $\lambda_1$, $\cdots$, $\lambda_n$, 不妨设其为从小到大的顺序 (交换 $P$ 的列顺序即可), 这些元素就是 $A$ 的特征值. $P$ 的列向量可以作为 $\R^n$ 的一组正交基, 记为 $x_1$, $\cdots$, $x_n$. $x$ 可以表示为 $x = \displaystyle\sum_{i = 1}^n \a_i x_i$, 有<br>\begin{align*}<br>x^\T Ax = (x, Ax) &amp;= \left( \displaystyle\sum_{i = 1}^n \a_i x_i, A\left( \displaystyle\sum_{i = 1}^n \a_i x_i \right) \right) = \left( \displaystyle\sum_{i = 1}^n \a_i x_i, \displaystyle\sum_{i = 1}^n \a_i Ax_i \right)\\<br>&amp;= \left( \displaystyle\sum_{i = 1}^n \a_i x_i, \displaystyle\sum_{i = 1}^n \a_i \lambda_i x_i \right) = \displaystyle\sum_{i = 1}^n \lambda_i \a_i^2 x_i^2 \geqslant \lambda_1 \displaystyle\sum_{i = 1}^n \a_i^2 x_i^2 = \lambda_1 x^\T x,<br>\end{align*}<br>其中 $(\cdot, \cdot)$ 表示内积. 于是 $f(x) \geqslant \lambda_1$, $x = \mu x_1$, $\mu \in \R \setminus \lrb{0}$ 时等号成立.<span style="float:right;">$\square$</span></p><h2 id="最优输送问题"><a href="#最优输送问题" class="headerlink" title="最优输送问题"></a>最优输送问题</h2><p>有四个工厂需要用煤, 用煤量分别为 $F_1$, $F_2$, $F_3$, $F_4$. 有三个煤矿, 矿产煤量分别为 $M_1$, $M_2$, $M_3$, 满足</p>\begin{equation*}M_1 + M_2 + M_3 = F_1 + F_2 + F_3 + F_4.\end{equation*}<p>设 $x_{ij}$, $i = 1, 2, 3$, $j = 1, 2, 3, 4$ 为 $i$ 矿到 $j$ 厂的运煤量, $d_{ij}$ 为 $i$ 矿到 $j$ 厂的距离, $c$ 为单位运费. 总运费为</p>\begin{equation*}f(x) = \sum_{i = 1}^{3}\sum_{j = 1}^{4} cx_{ij}d_{ij}.\end{equation*}<p>最优化问题为</p>\begin{equation*}\min_{x = x_{ij}} f(x),\quad \st \quad \begin{array}{ll}\displaystyle\sum_{i = 1}^{3} x_{ij} = F_j,    &    j = 1, 2, 3, 4,\\\displaystyle\sum_{j = 1}^{4} x_{ij} = M_i,    &    i = 1, 2, 3.\end{array}\end{equation*}<p>可以将这个问题写成矩阵形式</p>\begin{equation*}\min_{x \in \R^{12}} \tilde{c}^\T x, \quad \st \tilde{A}x = \tilde{b}.\end{equation*}<p><strong>习题 1.2</strong> 写出该最优化问题中的向量 $\tilde{c}$, $\tilde{b}$ 以及矩阵 $\tilde{A}$.</p><p><strong>解</strong> 设</p>\begin{equation*}x = \left( x_{11}, x_{12}, x_{13}, x_{14}, x_{21}, x_{22}, x_{23}, x_{24}, x_{31}, x_{32}, x_{33}, x_{34} \right)^\T ,\end{equation*}<p>则有<br>\begin{align*}<br>\tilde{c} &amp;= c \cdot \left( d_{11}, d_{12}, d_{13}, d_{14}, d_{21}, d_{22}, d_{23}, d_{24}, d_{31}, d_{32}, d_{33}, d_{34} \right)^\T ,\\<br>\tilde{b} &amp;= \left( F_1, F_2, F_3, F_4, M_1, M_2, M_3 \right)^\T ,\\<br>\tilde{A} &amp;= \begin{pmatrix}<br>1    &amp;    0    &amp;    0    &amp;    0    &amp;    1    &amp;    0    &amp;    0    &amp;    0    &amp;    1    &amp;    0    &amp;    0    &amp;    0\\<br>0    &amp;    1    &amp;    0    &amp;    0    &amp;    0    &amp;    1    &amp;    0    &amp;    0    &amp;    0    &amp;    1    &amp;    0    &amp;    0\\<br>0    &amp;    0    &amp;    1    &amp;    0    &amp;    0    &amp;    0    &amp;    1    &amp;    0    &amp;    0    &amp;    0    &amp;    1    &amp;    0\\<br>0    &amp;    0    &amp;    0    &amp;    1    &amp;    0    &amp;    0    &amp;    0    &amp;    1    &amp;    0    &amp;    0    &amp;    0    &amp;    1\\<br>1    &amp;    1    &amp;    1    &amp;    1    &amp;    0    &amp;    0    &amp;    0    &amp;    0    &amp;    0    &amp;    0    &amp;    0    &amp;    0\\<br>0    &amp;    0    &amp;    0    &amp;    0    &amp;    1    &amp;    1    &amp;    1    &amp;    1    &amp;    0    &amp;    0    &amp;    0    &amp;    0\\<br>0    &amp;    0    &amp;    0    &amp;    0    &amp;    0    &amp;    0    &amp;    0    &amp;    0    &amp;    1    &amp;    1    &amp;    1    &amp;    1<br>\end{pmatrix}.\tag*{$\square$}<br>\end{align*}</p><h2 id="人工神经网络"><a href="#人工神经网络" class="headerlink" title="人工神经网络"></a>人工神经网络</h2><p><img src="/img/OptimizationTheory/NN.png" srcset="/img/loading.gif" title="人工神经网络" alt="人工神经网络"></p><p>上图的人工神经网络构造了一个映射 $f : \R^2 \to \R$, $(x_1, x_2) \mapsto y$. 单个神经元如下图所示.<br><img src="/img/OptimizationTheory/Neu.png" srcset="/img/loading.gif" style="width:40%" title="神经元" alt="神经元"><br>它的作用为<br>\begin{align*}<br>    s &amp;= a_1w_1 + a_2w_2 + a_3w_3 + b,\\<br>    c &amp;= \dfrac{1}{1 + \e^{-s}}\quad (\text{Sigmoid 激活函数}).<br>\end{align*}</p><p><strong>习题 1.3</strong> 就上面这个简单的例子, 写出 $y = (x_1, x_2)$ 的显示形式.</p><p><strong>解</strong><br>\begin{align*}<br>y = \frac{1}{1 + \e^{-\left(\frac{w_7}{1 + \e^{-(x_1w_1 + x_2w_4 + b_1)}} + \frac{w_8}{1 + \e^{-(x_1w_2 + x_2w_5 + b_2)}} + \frac{w_9}{1 + \e^{-(x_1w_3 + x_2w_6 + b_3)}} + b_4\right)}}.\tag*{$\square$}<br>\end{align*}</p><p>如手写数字的识别, 将手写内容网格化成 $20 \times 20$ 的像素点, 若某个点被覆盖则取值为 $1$, 未被覆盖则取值为 $0$. 需要求解的函数为</p>\begin{equation*}h_{\bm w, \bm b} : \R^{400} \to \R^{10},\quad \bm \sg \mapsto \bm s,\end{equation*}<p>其中 $\bm \sg$ 为手写内容, $\bm s$ 为 $0 \sim 9$ 数字的概率, $\bm w$, $\bm b$ 为神经网络的参数. 给一定数量的手写内容及相应的数字对神经网络进行训练, 如 $\left( \bm \sg_i, \bm s_i \right)_{i = 1, \cdots, 3000}$, 最优化问题为</p>\begin{equation*}\min_{\bm w, \bm b} \sum_{i = 1}^{3000} \lrvv{h_{\bm w, \bm b}\left(\bm \sg_i \right) - \bm s_i}_{l^2}^2,\end{equation*}<p>求得的参数 $\bm w^*$, $\bm b^*$ 即为训练好的神经网络.</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>将实际问题建模得到最优化问题, 设计算法去实现并分析, 求得最小 (大) 值.</p><ul><li><p>可计算建模</p></li><li><p>算法与分析</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>Optimization Theory</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Optimization Theory</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Fourier 级数和积分</title>
    <link href="/2020/02/FourierAnalysis1/"/>
    <url>/2020/02/FourierAnalysis1/</url>
    
    <content type="html"><![CDATA[<p><strong>以下为 <em>Fourier Analysis</em> (Javier Duoandikoetxea) 的翻译结合老师的笔记.</strong> 本人英文渣, 所以翻译得可能不怎么样.</p><h1 id="Fourier-系数和级数"><a href="#Fourier-系数和级数" class="headerlink" title="Fourier 系数和级数"></a>Fourier 系数和级数</h1><p>当使用分离变量法解偏微分方程的时候会遇到将 $\R$ 上 (一个区间) 的函数表示为三角级数的问题<br>\begin{equation}\label{equ:realFour1}<br>f(x) = \displaystyle\sum_{k = 0}^\infty a_k \cos (kx) + b_k \sin (kx)<br>\end{equation}</p><p>这是 J. Fourier 在《热的解析理论》 (1822, 第一次解决问题是 1807 年在法兰西学会) 中给出了解决偏微分方程的这个方法. 更早的时候, 在 18 世纪中叶, Daniel Bernoulli 在解决振动弦的问题时曾提到这个方法, Fourier 系数的公式出现在 1777 年 L. Euler 的一篇文章中.</p><p>\eqref{equ:realFour1} 式的右边是一个 $2\pi$-周期函数, 所以 $f$ 也是 $2\pi$-周期函数. 因此我们考虑 $f$ 定义在一个 $2\pi$ 长度的区间上. 在 \eqref{equ:realFour1} 式中使用 Euler 恒等式 $\e^{\i kx} = \cos (kx) + \i \sin (kx)$, 我们可以用 $\lrb{\e^{\i kx}, k \in \Z}$ 来代替函数 $\sin (kx)$ 和 $\cos (kx)$, 从现在开始我们将这么做. 此外, 我将考虑 $1$-周期函数, 所以我们将修改函数系为 $\lrb{\e^{2\pi \i kx}, k \in \Z}$. 从而我们的问题变成了研究 $f$ 表示为<br>\begin{equation}\label{equ:imagFour1}<br>f(x) = \sum_{-\infty}^{\infty} c_k \e^{2\pi \i kx}.<br>\end{equation}</p><p>我们假设这个级数一致收敛, \eqref{equ:imagFour1} 式两边乘上 $\e^{-2\pi \i mx}$ 并在 $(0, 1)$ 上逐项积分得到</p>\begin{equation*}c_m = \int_{0}^{1} f(x)\e^{-2\pi\i mx} \di x,\end{equation*}<p>这是因为有如下正交关系</p>\begin{equation*}\int_{0}^{1}\e^{2 \pi \i kx}\e^{-2 \pi \i mx} \di x = \left\{\begin{array}{ll}0,    &    k \neq m,\\1,    &    k = m.\end{array}\right.\end{equation*}<p>记 $\bT$ 为实数模掉 $1$ 后的加群 ($\R / \Z$), 即一维圆环面. 它也可以看成是单位圆 $\bbS^1$. 我们说一个函数定义在 $\bT$ 上等价于说它定义在 $\R$ 上且周期为 $1$. 对于满足 $f \in L^1(\bT )$ 的函数我们可以定义一个数列 $\lrb{\hat{f}(k)}$, 若满足</p>\begin{equation*}\hat{f}(k) = \int_{0}^{1} f(x)\e^{-2\pi \i kx} \di x,\end{equation*}<p>则称其为 Fourier 系数. 由这些系数构成的三角级数<br>\begin{equation}\label{equ:fourSeri}<br>\sum_{-\infty}^{\infty}\hat{f}(k)\e^{2\pi \i kx}<br>\end{equation}</p><p>称为 $f$ 的 Fourier 级数.</p><p>现在，我们的问题在于确定级数 \eqref{equ:fourSeri} 何时以及在何种意义上表示函数 $f$.</p><!--设 $f$ 为 $\R$ 上 1-周期函数, 即$$f(x) = f(x + 1),\quad \forall x \in \R.$$问\begin{equation}\label{equ:realFour}f(x) = \displaystyle\sum_{k = 0}^\infty a_k \cos (2\pi kx) + b_k \sin (2\pi kx)\end{equation}在什么条件下成立? 由 \eqref{equ:realFour} 式及$$\e^{2 \pi \i kx} = \cos (2 \pi kx) + \i \sin (2 \pi kx)$$可得\begin{equation}\label{equ:imagFour}f(x) = \displaystyle\sum_{k = -\infty}^\infty c_k \e^{2 \pi \i kx},\end{equation}问 \eqref{equ:imagFour} 式在什么条件下?**Exercise 1** $\lrb{c_k}$ 与 $\lrb{a_k, b_k}$ 之间的关系是什么?=========================================================================## 为什么要研究这一问题或研究这一问题的有什么意义?Fourier 之所以研究这一问题是受到 (进行) 热传导研究的启发 (需要). 此处我们从 "信息" 的角度给一个动机:![alt 属性文本](/img/FA1.jpg "可选标题")方法之一: 把声音在不同频率的只记录下来, 即为 $c_k$.涉及以下两个问题.* $c_k = ?$* $\displaystyle\sum_{-\infty}^{\infty} c_k \e^{2\pi \i kx}$ 收敛性 / 速度? 是否收敛到 $f$.假设 $f$ 很好, 且假设级数一致收敛到 $f$, 那么$$c_k = \int_{0}^{1} f(x) \e^{-2 \pi \i kx} \di x$$***Proof*** 由$$c_k = \int_{0}^{1} f(x)\e^{-2 \pi \i kx} \di x = \sum_{-\infty}^{\infty} c_l \int_0^1 \e^{2 \pi \i lx}\e^{-2 \pi \i kx}\di x$$而一般地, 设 $f \in L^1(\mathbb{T})$ ($f$ 周期为 1 且 $f$ 在 $[0, 1]$ 上可积, Lebesgue 意义下 $\displaystyle\int_0^1 |f| \di x < \infty$). 定义 $f$ 的 Fourier 系数为$$\hat{f}(k) = \int_{0}^{1}f(x)\e^{-2\pi\i kx}\di x \forall k \in \Z \left(\hat{f}(k) \leq \lrvv{f}_{L^1(\mathbb{T})} = \int_{0}^{1}\lrv{f} \di x \right),$$$f$ 对应的 Fourier 级数为$$\sum_{-\infty}^{\infty} \hat{f}(k)\e^{2 \pi \i kx}.$$在 $f \in L^1(\mathbb{T})$ 的假设下, 我们将研究 $f$ 的 Fourier 级数的收敛性.# Riemann-Lebesgue Lemma设 $f \in L^1(\mathbb{T})$, 则 $\hat{f}(k) \to 0$, $\lrv{k} \to \infty$.***Proof***若 $f$ 连续, 那么$$\lim_{\lrv{k} \to \infty} \hat{f}(k) \xle{Lebesgue 控制收敛定理} = \frac{1}{2} \lim_{\lrv{k} \to \infty}\left( \right)$$若 $f \in L^1^(\bT)$, 知对任意 $\ep > 0$, 存在连续函数使得$$$$# 逐点收敛准则***Theorem*** (Jordan 准则) 假定 $x \in [0, 1)$***Exercise 2*** 设 $f \in \BV [a, b]$, 证明 $f$ 有界, 且对于任意 $x \in [a, b)$, $f(x+) := \lim_{y \to x+} f(y)$ 存在, 对于任意 $x \in (a, b]$, $f(x-) := \lim_{y \to x-} f(y)$ 存在.***Exercise 3***为证明上述三个准则-->]]></content>
    
    
    <categories>
      
      <category>Fourier Analysis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Fourier Analysis</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>